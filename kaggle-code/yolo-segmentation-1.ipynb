{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4509640,"sourceType":"datasetVersion","datasetId":2619393}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:01:29.870714Z","iopub.execute_input":"2025-11-08T04:01:29.871204Z","iopub.status.idle":"2025-11-08T04:01:31.588541Z","shell.execute_reply.started":"2025-11-08T04:01:29.871177Z","shell.execute_reply":"2025-11-08T04:01:31.587983Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/medical-segmentation-decathlon-lung/._labelsTr\n/kaggle/input/medical-segmentation-decathlon-lung/._imagesTr\n/kaggle/input/medical-segmentation-decathlon-lung/._imagesTs\n/kaggle/input/medical-segmentation-decathlon-lung/._dataset.json\n/kaggle/input/medical-segmentation-decathlon-lung/dataset.json\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_040.nii/lung_040.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_052.nii/lung_052.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_088.nii/lung_088.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_067.nii/lung_067.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_089.nii/lung_089.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_068.nii/lung_068.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_056.nii/lung_056.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_087.nii/lung_087.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_076.nii/lung_076.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_063.nii/lung_063.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_077.nii/lung_077.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_030.nii/lung_030.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_002.nii/lung_002.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_032.nii/lung_032.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_019.nii/lung_019.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_072.nii/lung_072.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_012.nii/lung_012.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_008.nii/lung_008.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_021.nii/lung_021.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_011.nii/lung_011.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_085.nii/lung_085.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_007.nii/lung_007.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_082.nii/lung_082.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_090.nii/lung_090.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_035.nii/lung_035.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_013.nii/lung_013.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_017.nii/lung_017.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_039.nii/lung_039.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_024.nii/lung_024.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_060.nii/lung_060.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_050.nii/lung_050.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTs/lung_091.nii/lung_091.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_065.nii/lung_065.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_022.nii/lung_022.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_051.nii/lung_051.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_061.nii/lung_061.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_043.nii/lung_043.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_059.nii/lung_059.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_015.nii/lung_015.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_053.nii/lung_053.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_023.nii/lung_023.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_049.nii/lung_049.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_044.nii/lung_044.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_084.nii/lung_084.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_025.nii/lung_025.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_086.nii/lung_086.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_018.nii/lung_018.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_092.nii/lung_092.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_064.nii/lung_064.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_069.nii/lung_069.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_037.nii/lung_037.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_080.nii/lung_080.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_081.nii/lung_081.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_031.nii/lung_031.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_070.nii/lung_070.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_045.nii/lung_045.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_074.nii/lung_074.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_034.nii/lung_034.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_028.nii/lung_028.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_046.nii/lung_046.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_096.nii/lung_096.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_078.nii/lung_078.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_079.nii/lung_079.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_066.nii/lung_066.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_027.nii/lung_027.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_004.nii/lung_004.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_048.nii/lung_048.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_058.nii/lung_058.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_026.nii/lung_026.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_071.nii/lung_071.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_014.nii/lung_014.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_062.nii/lung_062.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_033.nii/lung_033.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_093.nii/lung_093.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_036.nii/lung_036.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_010.nii/lung_010.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_003.nii/lung_003.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_083.nii/lung_083.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_042.nii/lung_042.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_075.nii/lung_075.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_009.nii/lung_009.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_005.nii/lung_005.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_047.nii/lung_047.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_020.nii/lung_020.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_001.nii/lung_001.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_029.nii/lung_029.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_055.nii/lung_055.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_016.nii/lung_016.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_054.nii/lung_054.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_038.nii/lung_038.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_073.nii/lung_073.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_006.nii/lung_006.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_057.nii/lung_057.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_041.nii/lung_041.nii\n/kaggle/input/medical-segmentation-decathlon-lung/labelsTr/lung_095.nii/lung_095.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_065.nii/lung_065.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_022.nii/lung_022.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_051.nii/lung_051.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_061.nii/lung_061.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_043.nii/lung_043.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_059.nii/lung_059.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_015.nii/lung_015.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_053.nii/lung_053.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_023.nii/lung_023.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_049.nii/lung_049.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_044.nii/lung_044.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_084.nii/lung_084.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_025.nii/lung_025.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_086.nii/lung_086.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_018.nii/lung_018.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_092.nii/lung_092.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_064.nii/lung_064.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_069.nii/lung_069.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_037.nii/lung_037.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_080.nii/lung_080.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_081.nii/lung_081.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_031.nii/lung_031.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_070.nii/lung_070.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_045.nii/lung_045.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_074.nii/lung_074.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_034.nii/lung_034.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_028.nii/lung_028.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_046.nii/lung_046.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_096.nii/lung_096.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_078.nii/lung_078.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_079.nii/lung_079.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_066.nii/lung_066.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_027.nii/lung_027.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_004.nii/lung_004.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_048.nii/lung_048.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_058.nii/lung_058.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_026.nii/lung_026.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_071.nii/lung_071.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_014.nii/lung_014.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_062.nii/lung_062.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_033.nii/lung_033.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_093.nii/lung_093.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_036.nii/lung_036.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_010.nii/lung_010.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_003.nii/lung_003.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_083.nii/lung_083.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_042.nii/lung_042.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_075.nii/lung_075.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_009.nii/lung_009.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_005.nii/lung_005.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_047.nii/lung_047.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_020.nii/lung_020.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_001.nii/lung_001.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_029.nii/lung_029.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_055.nii/lung_055.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_016.nii/lung_016.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_054.nii/lung_054.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_038.nii/lung_038.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_073.nii/lung_073.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_006.nii/lung_006.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_057.nii/lung_057.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_041.nii/lung_041.nii\n/kaggle/input/medical-segmentation-decathlon-lung/imagesTr/lung_095.nii/lung_095.nii\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!apt-get update && apt-get install -y tree\n!tree /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:01:31.589768Z","iopub.execute_input":"2025-11-08T04:01:31.590144Z","iopub.status.idle":"2025-11-08T04:01:42.337676Z","shell.execute_reply.started":"2025-11-08T04:01:31.590126Z","shell.execute_reply":"2025-11-08T04:01:42.336811Z"}},"outputs":[{"name":"stdout","text":"Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\nGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\nGet:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\nGet:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]        \nGet:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]           \nGet:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]      \nGet:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]      \nGet:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,123 kB]\nGet:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.2 kB]\nGet:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\nGet:11 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,825 kB]\nGet:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\nGet:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,856 kB]\nGet:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,432 kB] \nHit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease   \nGet:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\nGet:17 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,168 kB]\nGet:18 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.2 kB]\nGet:19 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\nGet:20 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.9 kB]\nGet:21 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,526 kB]\nGet:22 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\nGet:23 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [44.9 kB]\nGet:24 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\nGet:25 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,969 kB]\nGet:26 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [60.9 kB]\nFetched 37.6 MB in 3s (12.8 MB/s)                            \nReading package lists... Done\nW: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nThe following NEW packages will be installed:\n  tree\n0 upgraded, 1 newly installed, 0 to remove and 212 not upgraded.\nNeed to get 47.9 kB of archives.\nAfter this operation, 116 kB of additional disk space will be used.\nGet:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\nFetched 47.9 kB in 0s (346 kB/s)\nSelecting previously unselected package tree.\n(Reading database ... 128663 files and directories currently installed.)\nPreparing to unpack .../tree_2.0.2-1_amd64.deb ...\nUnpacking tree (2.0.2-1) ...\nSetting up tree (2.0.2-1) ...\nProcessing triggers for man-db (2.10.2-1) ...\n\u001b[01;34m/kaggle/input/\u001b[0m\n└── \u001b[01;34mmedical-segmentation-decathlon-lung\u001b[0m\n    ├── \u001b[00mdataset.json\u001b[0m\n    ├── \u001b[01;34mimagesTr\u001b[0m\n    │   ├── \u001b[01;34mlung_001.nii\u001b[0m\n    │   │   └── \u001b[00mlung_001.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_003.nii\u001b[0m\n    │   │   └── \u001b[00mlung_003.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_004.nii\u001b[0m\n    │   │   └── \u001b[00mlung_004.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_005.nii\u001b[0m\n    │   │   └── \u001b[00mlung_005.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_006.nii\u001b[0m\n    │   │   └── \u001b[00mlung_006.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_009.nii\u001b[0m\n    │   │   └── \u001b[00mlung_009.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_010.nii\u001b[0m\n    │   │   └── \u001b[00mlung_010.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_014.nii\u001b[0m\n    │   │   └── \u001b[00mlung_014.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_015.nii\u001b[0m\n    │   │   └── \u001b[00mlung_015.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_016.nii\u001b[0m\n    │   │   └── \u001b[00mlung_016.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_018.nii\u001b[0m\n    │   │   └── \u001b[00mlung_018.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_020.nii\u001b[0m\n    │   │   └── \u001b[00mlung_020.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_022.nii\u001b[0m\n    │   │   └── \u001b[00mlung_022.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_023.nii\u001b[0m\n    │   │   └── \u001b[00mlung_023.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_025.nii\u001b[0m\n    │   │   └── \u001b[00mlung_025.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_026.nii\u001b[0m\n    │   │   └── \u001b[00mlung_026.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_027.nii\u001b[0m\n    │   │   └── \u001b[00mlung_027.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_028.nii\u001b[0m\n    │   │   └── \u001b[00mlung_028.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_029.nii\u001b[0m\n    │   │   └── \u001b[00mlung_029.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_031.nii\u001b[0m\n    │   │   └── \u001b[00mlung_031.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_033.nii\u001b[0m\n    │   │   └── \u001b[00mlung_033.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_034.nii\u001b[0m\n    │   │   └── \u001b[00mlung_034.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_036.nii\u001b[0m\n    │   │   └── \u001b[00mlung_036.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_037.nii\u001b[0m\n    │   │   └── \u001b[00mlung_037.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_038.nii\u001b[0m\n    │   │   └── \u001b[00mlung_038.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_041.nii\u001b[0m\n    │   │   └── \u001b[00mlung_041.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_042.nii\u001b[0m\n    │   │   └── \u001b[00mlung_042.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_043.nii\u001b[0m\n    │   │   └── \u001b[00mlung_043.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_044.nii\u001b[0m\n    │   │   └── \u001b[00mlung_044.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_045.nii\u001b[0m\n    │   │   └── \u001b[00mlung_045.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_046.nii\u001b[0m\n    │   │   └── \u001b[00mlung_046.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_047.nii\u001b[0m\n    │   │   └── \u001b[00mlung_047.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_048.nii\u001b[0m\n    │   │   └── \u001b[00mlung_048.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_049.nii\u001b[0m\n    │   │   └── \u001b[00mlung_049.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_051.nii\u001b[0m\n    │   │   └── \u001b[00mlung_051.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_053.nii\u001b[0m\n    │   │   └── \u001b[00mlung_053.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_054.nii\u001b[0m\n    │   │   └── \u001b[00mlung_054.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_055.nii\u001b[0m\n    │   │   └── \u001b[00mlung_055.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_057.nii\u001b[0m\n    │   │   └── \u001b[00mlung_057.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_058.nii\u001b[0m\n    │   │   └── \u001b[00mlung_058.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_059.nii\u001b[0m\n    │   │   └── \u001b[00mlung_059.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_061.nii\u001b[0m\n    │   │   └── \u001b[00mlung_061.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_062.nii\u001b[0m\n    │   │   └── \u001b[00mlung_062.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_064.nii\u001b[0m\n    │   │   └── \u001b[00mlung_064.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_065.nii\u001b[0m\n    │   │   └── \u001b[00mlung_065.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_066.nii\u001b[0m\n    │   │   └── \u001b[00mlung_066.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_069.nii\u001b[0m\n    │   │   └── \u001b[00mlung_069.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_070.nii\u001b[0m\n    │   │   └── \u001b[00mlung_070.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_071.nii\u001b[0m\n    │   │   └── \u001b[00mlung_071.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_073.nii\u001b[0m\n    │   │   └── \u001b[00mlung_073.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_074.nii\u001b[0m\n    │   │   └── \u001b[00mlung_074.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_075.nii\u001b[0m\n    │   │   └── \u001b[00mlung_075.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_078.nii\u001b[0m\n    │   │   └── \u001b[00mlung_078.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_079.nii\u001b[0m\n    │   │   └── \u001b[00mlung_079.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_080.nii\u001b[0m\n    │   │   └── \u001b[00mlung_080.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_081.nii\u001b[0m\n    │   │   └── \u001b[00mlung_081.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_083.nii\u001b[0m\n    │   │   └── \u001b[00mlung_083.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_084.nii\u001b[0m\n    │   │   └── \u001b[00mlung_084.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_086.nii\u001b[0m\n    │   │   └── \u001b[00mlung_086.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_092.nii\u001b[0m\n    │   │   └── \u001b[00mlung_092.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_093.nii\u001b[0m\n    │   │   └── \u001b[00mlung_093.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_095.nii\u001b[0m\n    │   │   └── \u001b[00mlung_095.nii\u001b[0m\n    │   └── \u001b[01;34mlung_096.nii\u001b[0m\n    │       └── \u001b[00mlung_096.nii\u001b[0m\n    ├── \u001b[01;34mimagesTs\u001b[0m\n    │   ├── \u001b[01;34mlung_002.nii\u001b[0m\n    │   │   └── \u001b[00mlung_002.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_007.nii\u001b[0m\n    │   │   └── \u001b[00mlung_007.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_008.nii\u001b[0m\n    │   │   └── \u001b[00mlung_008.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_011.nii\u001b[0m\n    │   │   └── \u001b[00mlung_011.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_012.nii\u001b[0m\n    │   │   └── \u001b[00mlung_012.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_013.nii\u001b[0m\n    │   │   └── \u001b[00mlung_013.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_017.nii\u001b[0m\n    │   │   └── \u001b[00mlung_017.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_019.nii\u001b[0m\n    │   │   └── \u001b[00mlung_019.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_021.nii\u001b[0m\n    │   │   └── \u001b[00mlung_021.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_024.nii\u001b[0m\n    │   │   └── \u001b[00mlung_024.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_030.nii\u001b[0m\n    │   │   └── \u001b[00mlung_030.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_032.nii\u001b[0m\n    │   │   └── \u001b[00mlung_032.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_035.nii\u001b[0m\n    │   │   └── \u001b[00mlung_035.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_039.nii\u001b[0m\n    │   │   └── \u001b[00mlung_039.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_040.nii\u001b[0m\n    │   │   └── \u001b[00mlung_040.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_050.nii\u001b[0m\n    │   │   └── \u001b[00mlung_050.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_052.nii\u001b[0m\n    │   │   └── \u001b[00mlung_052.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_056.nii\u001b[0m\n    │   │   └── \u001b[00mlung_056.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_060.nii\u001b[0m\n    │   │   └── \u001b[00mlung_060.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_063.nii\u001b[0m\n    │   │   └── \u001b[00mlung_063.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_067.nii\u001b[0m\n    │   │   └── \u001b[00mlung_067.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_068.nii\u001b[0m\n    │   │   └── \u001b[00mlung_068.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_072.nii\u001b[0m\n    │   │   └── \u001b[00mlung_072.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_076.nii\u001b[0m\n    │   │   └── \u001b[00mlung_076.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_077.nii\u001b[0m\n    │   │   └── \u001b[00mlung_077.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_082.nii\u001b[0m\n    │   │   └── \u001b[00mlung_082.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_085.nii\u001b[0m\n    │   │   └── \u001b[00mlung_085.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_087.nii\u001b[0m\n    │   │   └── \u001b[00mlung_087.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_088.nii\u001b[0m\n    │   │   └── \u001b[00mlung_088.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_089.nii\u001b[0m\n    │   │   └── \u001b[00mlung_089.nii\u001b[0m\n    │   ├── \u001b[01;34mlung_090.nii\u001b[0m\n    │   │   └── \u001b[00mlung_090.nii\u001b[0m\n    │   └── \u001b[01;34mlung_091.nii\u001b[0m\n    │       └── \u001b[00mlung_091.nii\u001b[0m\n    └── \u001b[01;34mlabelsTr\u001b[0m\n        ├── \u001b[01;34mlung_001.nii\u001b[0m\n        │   └── \u001b[00mlung_001.nii\u001b[0m\n        ├── \u001b[01;34mlung_003.nii\u001b[0m\n        │   └── \u001b[00mlung_003.nii\u001b[0m\n        ├── \u001b[01;34mlung_004.nii\u001b[0m\n        │   └── \u001b[00mlung_004.nii\u001b[0m\n        ├── \u001b[01;34mlung_005.nii\u001b[0m\n        │   └── \u001b[00mlung_005.nii\u001b[0m\n        ├── \u001b[01;34mlung_006.nii\u001b[0m\n        │   └── \u001b[00mlung_006.nii\u001b[0m\n        ├── \u001b[01;34mlung_009.nii\u001b[0m\n        │   └── \u001b[00mlung_009.nii\u001b[0m\n        ├── \u001b[01;34mlung_010.nii\u001b[0m\n        │   └── \u001b[00mlung_010.nii\u001b[0m\n        ├── \u001b[01;34mlung_014.nii\u001b[0m\n        │   └── \u001b[00mlung_014.nii\u001b[0m\n        ├── \u001b[01;34mlung_015.nii\u001b[0m\n        │   └── \u001b[00mlung_015.nii\u001b[0m\n        ├── \u001b[01;34mlung_016.nii\u001b[0m\n        │   └── \u001b[00mlung_016.nii\u001b[0m\n        ├── \u001b[01;34mlung_018.nii\u001b[0m\n        │   └── \u001b[00mlung_018.nii\u001b[0m\n        ├── \u001b[01;34mlung_020.nii\u001b[0m\n        │   └── \u001b[00mlung_020.nii\u001b[0m\n        ├── \u001b[01;34mlung_022.nii\u001b[0m\n        │   └── \u001b[00mlung_022.nii\u001b[0m\n        ├── \u001b[01;34mlung_023.nii\u001b[0m\n        │   └── \u001b[00mlung_023.nii\u001b[0m\n        ├── \u001b[01;34mlung_025.nii\u001b[0m\n        │   └── \u001b[00mlung_025.nii\u001b[0m\n        ├── \u001b[01;34mlung_026.nii\u001b[0m\n        │   └── \u001b[00mlung_026.nii\u001b[0m\n        ├── \u001b[01;34mlung_027.nii\u001b[0m\n        │   └── \u001b[00mlung_027.nii\u001b[0m\n        ├── \u001b[01;34mlung_028.nii\u001b[0m\n        │   └── \u001b[00mlung_028.nii\u001b[0m\n        ├── \u001b[01;34mlung_029.nii\u001b[0m\n        │   └── \u001b[00mlung_029.nii\u001b[0m\n        ├── \u001b[01;34mlung_031.nii\u001b[0m\n        │   └── \u001b[00mlung_031.nii\u001b[0m\n        ├── \u001b[01;34mlung_033.nii\u001b[0m\n        │   └── \u001b[00mlung_033.nii\u001b[0m\n        ├── \u001b[01;34mlung_034.nii\u001b[0m\n        │   └── \u001b[00mlung_034.nii\u001b[0m\n        ├── \u001b[01;34mlung_036.nii\u001b[0m\n        │   └── \u001b[00mlung_036.nii\u001b[0m\n        ├── \u001b[01;34mlung_037.nii\u001b[0m\n        │   └── \u001b[00mlung_037.nii\u001b[0m\n        ├── \u001b[01;34mlung_038.nii\u001b[0m\n        │   └── \u001b[00mlung_038.nii\u001b[0m\n        ├── \u001b[01;34mlung_041.nii\u001b[0m\n        │   └── \u001b[00mlung_041.nii\u001b[0m\n        ├── \u001b[01;34mlung_042.nii\u001b[0m\n        │   └── \u001b[00mlung_042.nii\u001b[0m\n        ├── \u001b[01;34mlung_043.nii\u001b[0m\n        │   └── \u001b[00mlung_043.nii\u001b[0m\n        ├── \u001b[01;34mlung_044.nii\u001b[0m\n        │   └── \u001b[00mlung_044.nii\u001b[0m\n        ├── \u001b[01;34mlung_045.nii\u001b[0m\n        │   └── \u001b[00mlung_045.nii\u001b[0m\n        ├── \u001b[01;34mlung_046.nii\u001b[0m\n        │   └── \u001b[00mlung_046.nii\u001b[0m\n        ├── \u001b[01;34mlung_047.nii\u001b[0m\n        │   └── \u001b[00mlung_047.nii\u001b[0m\n        ├── \u001b[01;34mlung_048.nii\u001b[0m\n        │   └── \u001b[00mlung_048.nii\u001b[0m\n        ├── \u001b[01;34mlung_049.nii\u001b[0m\n        │   └── \u001b[00mlung_049.nii\u001b[0m\n        ├── \u001b[01;34mlung_051.nii\u001b[0m\n        │   └── \u001b[00mlung_051.nii\u001b[0m\n        ├── \u001b[01;34mlung_053.nii\u001b[0m\n        │   └── \u001b[00mlung_053.nii\u001b[0m\n        ├── \u001b[01;34mlung_054.nii\u001b[0m\n        │   └── \u001b[00mlung_054.nii\u001b[0m\n        ├── \u001b[01;34mlung_055.nii\u001b[0m\n        │   └── \u001b[00mlung_055.nii\u001b[0m\n        ├── \u001b[01;34mlung_057.nii\u001b[0m\n        │   └── \u001b[00mlung_057.nii\u001b[0m\n        ├── \u001b[01;34mlung_058.nii\u001b[0m\n        │   └── \u001b[00mlung_058.nii\u001b[0m\n        ├── \u001b[01;34mlung_059.nii\u001b[0m\n        │   └── \u001b[00mlung_059.nii\u001b[0m\n        ├── \u001b[01;34mlung_061.nii\u001b[0m\n        │   └── \u001b[00mlung_061.nii\u001b[0m\n        ├── \u001b[01;34mlung_062.nii\u001b[0m\n        │   └── \u001b[00mlung_062.nii\u001b[0m\n        ├── \u001b[01;34mlung_064.nii\u001b[0m\n        │   └── \u001b[00mlung_064.nii\u001b[0m\n        ├── \u001b[01;34mlung_065.nii\u001b[0m\n        │   └── \u001b[00mlung_065.nii\u001b[0m\n        ├── \u001b[01;34mlung_066.nii\u001b[0m\n        │   └── \u001b[00mlung_066.nii\u001b[0m\n        ├── \u001b[01;34mlung_069.nii\u001b[0m\n        │   └── \u001b[00mlung_069.nii\u001b[0m\n        ├── \u001b[01;34mlung_070.nii\u001b[0m\n        │   └── \u001b[00mlung_070.nii\u001b[0m\n        ├── \u001b[01;34mlung_071.nii\u001b[0m\n        │   └── \u001b[00mlung_071.nii\u001b[0m\n        ├── \u001b[01;34mlung_073.nii\u001b[0m\n        │   └── \u001b[00mlung_073.nii\u001b[0m\n        ├── \u001b[01;34mlung_074.nii\u001b[0m\n        │   └── \u001b[00mlung_074.nii\u001b[0m\n        ├── \u001b[01;34mlung_075.nii\u001b[0m\n        │   └── \u001b[00mlung_075.nii\u001b[0m\n        ├── \u001b[01;34mlung_078.nii\u001b[0m\n        │   └── \u001b[00mlung_078.nii\u001b[0m\n        ├── \u001b[01;34mlung_079.nii\u001b[0m\n        │   └── \u001b[00mlung_079.nii\u001b[0m\n        ├── \u001b[01;34mlung_080.nii\u001b[0m\n        │   └── \u001b[00mlung_080.nii\u001b[0m\n        ├── \u001b[01;34mlung_081.nii\u001b[0m\n        │   └── \u001b[00mlung_081.nii\u001b[0m\n        ├── \u001b[01;34mlung_083.nii\u001b[0m\n        │   └── \u001b[00mlung_083.nii\u001b[0m\n        ├── \u001b[01;34mlung_084.nii\u001b[0m\n        │   └── \u001b[00mlung_084.nii\u001b[0m\n        ├── \u001b[01;34mlung_086.nii\u001b[0m\n        │   └── \u001b[00mlung_086.nii\u001b[0m\n        ├── \u001b[01;34mlung_092.nii\u001b[0m\n        │   └── \u001b[00mlung_092.nii\u001b[0m\n        ├── \u001b[01;34mlung_093.nii\u001b[0m\n        │   └── \u001b[00mlung_093.nii\u001b[0m\n        ├── \u001b[01;34mlung_095.nii\u001b[0m\n        │   └── \u001b[00mlung_095.nii\u001b[0m\n        └── \u001b[01;34mlung_096.nii\u001b[0m\n            └── \u001b[00mlung_096.nii\u001b[0m\n\n162 directories, 159 files\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Install required packages\n%pip install ultralytics nibabel scikit-image opencv-python-headless tqdm\n\nimport os\nimport glob\nimport numpy as np\nimport nibabel as nib\nimport cv2\nfrom tqdm import tqdm\nfrom ultralytics import YOLO\nfrom sklearn.model_selection import train_test_split\nimport yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:01:42.338753Z","iopub.execute_input":"2025-11-08T04:01:42.339074Z","iopub.status.idle":"2025-11-08T04:03:03.059217Z","shell.execute_reply.started":"2025-11-08T04:01:42.339039Z","shell.execute_reply":"2025-11-08T04:03:03.058561Z"}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.3.226-py3-none-any.whl.metadata (37 kB)\nRequirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.7.2)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.4)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (7.0.0)\nRequirement already satisfied: polars in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.21.0)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\nRequirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (25.0)\nRequirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.14.0)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.5)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.6.11)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.4)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.0->ultralytics) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.6.15)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.5.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.0->ultralytics) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.0->ultralytics) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.0->ultralytics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.0->ultralytics) (2024.2.0)\nDownloading ultralytics-8.3.226-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.226 ultralytics-thop-2.0.18\nNote: you may need to restart the kernel to use updated packages.\nCreating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- Define Input Paths ---\nDATA_DIR = \"/kaggle/input/medical-segmentation-decathlon-lung/\"\nIMAGE_DIR = os.path.join(DATA_DIR, \"imagesTr\")\nLABEL_DIR = os.path.join(DATA_DIR, \"labelsTr\")\n\n# Find all the NIfTI files using the nested pattern\n# This uses the same glob pattern that worked for you before\nimage_paths = sorted(glob.glob(os.path.join(IMAGE_DIR, \"*/*.nii\")))\nlabel_paths = sorted(glob.glob(os.path.join(LABEL_DIR, \"*/*.nii\")))\n\n# --- Define Output Paths for YOLO Dataset ---\n# We'll create our processed dataset in the /kaggle/working/ directory\nYOLO_DATA_DIR = \"/kaggle/working/lung_dataset_yolo/\"\nos.makedirs(YOLO_DATA_DIR, exist_ok=True)\nfor sub in ['train', 'val']:\n    os.makedirs(os.path.join(YOLO_DATA_DIR, 'images', sub), exist_ok=True)\n    os.makedirs(os.path.join(YOLO_DATA_DIR, 'labels', sub), exist_ok=True)\n\nprint(\"YOLO directory structure created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:03:03.060103Z","iopub.execute_input":"2025-11-08T04:03:03.060476Z","iopub.status.idle":"2025-11-08T04:03:03.220019Z","shell.execute_reply.started":"2025-11-08T04:03:03.060440Z","shell.execute_reply":"2025-11-08T04:03:03.219437Z"}},"outputs":[{"name":"stdout","text":"YOLO directory structure created successfully.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Cell 3 (Corrected Version)\n\ndef convert_nii_to_yolo(image_path, label_path, output_img_dir, output_lbl_dir, patient_id):\n    \"\"\"\n    Converts a single 3D NIfTI scan and its label into 2D slices in YOLO format.\n    \"\"\"\n    img_nii = nib.load(image_path)\n    lbl_nii = nib.load(label_path)\n    image_data = img_nii.get_fdata()\n    label_data = lbl_nii.get_fdata()\n\n    for i in range(image_data.shape[2]):\n        slice_label = label_data[:, :, i]\n\n        if np.sum(slice_label) > 0:\n            slice_image = image_data[:, :, i]\n            slice_image_normalized = cv2.normalize(slice_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n            slice_image_rgb = cv2.cvtColor(slice_image_normalized, cv2.COLOR_GRAY2BGR)\n            img_filename = f\"{patient_id}_slice_{i}.png\"\n            cv2.imwrite(os.path.join(output_img_dir, img_filename), slice_image_rgb)\n\n            contours, _ = cv2.findContours(slice_label.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            label_filename = f\"{patient_id}_slice_{i}.txt\"\n            h, w = slice_label.shape\n\n            with open(os.path.join(output_lbl_dir, label_filename), 'w') as f:\n                for contour in contours:\n                    # --- THIS IS THE FIX ---\n                    # Only write polygons with 3 or more points\n                    if contour.shape[0] >= 3:\n                        f.write(\"0\")\n                        points = contour.flatten()\n                        for j in range(0, len(points), 2):\n                            x = points[j] / w\n                            y = points[j+1] / h\n                            f.write(f\" {x:.6f} {y:.6f}\")\n                        f.write(\"\\n\")\n\nprint(\"Conversion function is ready.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:03:03.221986Z","iopub.execute_input":"2025-11-08T04:03:03.222193Z","iopub.status.idle":"2025-11-08T04:03:03.229593Z","shell.execute_reply.started":"2025-11-08T04:03:03.222177Z","shell.execute_reply":"2025-11-08T04:03:03.228980Z"}},"outputs":[{"name":"stdout","text":"Conversion function is ready.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Split the original NIfTI files into training and validation sets\ntrain_img_paths, val_img_paths, train_lbl_paths, val_lbl_paths = train_test_split(\n    image_paths, label_paths, test_size=0.2, random_state=42\n)\n\n# Process the training set\nprint(\"Processing training data...\")\nfor img_p, lbl_p in tqdm(zip(train_img_paths, train_lbl_paths), total=len(train_img_paths)):\n    patient_id = os.path.basename(os.path.dirname(img_p)) # e.g., 'lung_001.nii'\n    convert_nii_to_yolo(img_p, lbl_p, \n                        os.path.join(YOLO_DATA_DIR, 'images', 'train'), \n                        os.path.join(YOLO_DATA_DIR, 'labels', 'train'), \n                        patient_id)\n\n# Process the validation set\nprint(\"\\nProcessing validation data...\")\nfor img_p, lbl_p in tqdm(zip(val_img_paths, val_lbl_paths), total=len(val_img_paths)):\n    patient_id = os.path.basename(os.path.dirname(img_p))\n    convert_nii_to_yolo(img_p, lbl_p, \n                        os.path.join(YOLO_DATA_DIR, 'images', 'val'), \n                        os.path.join(YOLO_DATA_DIR, 'labels', 'val'), \n                        patient_id)\n\nprint(\"\\nData conversion complete!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:03:03.230316Z","iopub.execute_input":"2025-11-08T04:03:03.231098Z","iopub.status.idle":"2025-11-08T04:09:09.423070Z","shell.execute_reply.started":"2025-11-08T04:03:03.231080Z","shell.execute_reply":"2025-11-08T04:09:09.422309Z"}},"outputs":[{"name":"stdout","text":"Processing training data...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 50/50 [04:54<00:00,  5.89s/it]\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing validation data...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 13/13 [01:11<00:00,  5.51s/it]","output_type":"stream"},{"name":"stdout","text":"\nData conversion complete!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Create the YAML configuration file\ndata_yaml = {\n    'train': '../lung_dataset_yolo/images/train',\n    'val': '../lung_dataset_yolo/images/val',\n    'nc': 1,  # Number of classes\n    'names': ['tumor']  # Class names\n}\n\nwith open(os.path.join(YOLO_DATA_DIR, 'data.yaml'), 'w') as f:\n    yaml.dump(data_yaml, f)\n\nprint(\"data.yaml file created successfully:\")\n!cat /kaggle/working/lung_dataset_yolo/data.yaml","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:09:09.424008Z","iopub.execute_input":"2025-11-08T04:09:09.424410Z","iopub.status.idle":"2025-11-08T04:09:09.564706Z","shell.execute_reply.started":"2025-11-08T04:09:09.424382Z","shell.execute_reply":"2025-11-08T04:09:09.563996Z"}},"outputs":[{"name":"stdout","text":"data.yaml file created successfully:\nnames:\n- tumor\nnc: 1\ntrain: ../lung_dataset_yolo/images/train\nval: ../lung_dataset_yolo/images/val\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Load a pretrained YOLOv8 segmentation model\nmodel = YOLO('yolov8n-seg.pt')\n\n# Train the model\nresults = model.train(\n    data=os.path.join(YOLO_DATA_DIR, 'data.yaml'),\n    epochs=50,      # Number of training epochs\n    imgsz=512,      # Image size for training\n    batch=16,       # Batch size\n    name='yolov8_lung_seg' # Name for the training run\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:09:09.565894Z","iopub.execute_input":"2025-11-08T04:09:09.566198Z","iopub.status.idle":"2025-11-08T04:23:08.905617Z","shell.execute_reply.started":"2025-11-08T04:09:09.566170Z","shell.execute_reply":"2025-11-08T04:23:08.904838Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.226 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/kaggle/working/lung_dataset_yolo/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=512, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8_lung_seg7, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/segment/yolov8_lung_seg7, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 16.9MB/s 0.0s\nOverriding model.yaml nc=80 with nc=1\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n 22        [15, 18, 21]  1   1004275  ultralytics.nn.modules.head.Segment          [1, 32, 64, [64, 128, 256]]   \nYOLOv8n-seg summary: 151 layers, 3,263,811 parameters, 3,263,795 gradients, 11.5 GFLOPs\n\nTransferred 381/417 items from pretrained weights\nFreezing layer 'model.22.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2380.7±904.2 MB/s, size: 358.0 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/lung_dataset_yolo/labels/train.cache... 1261 images, 13 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 1261/1261 2.9Mit/s 0.0s0s\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1099.8±1248.7 MB/s, size: 370.9 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/lung_dataset_yolo/labels/val.cache... 396 images, 2 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 396/396 545.5Kit/s 0.0s\nPlotting labels to /kaggle/working/runs/segment/yolov8_lung_seg7/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\nImage sizes 512 train, 512 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/segment/yolov8_lung_seg7\u001b[0m\nStarting training for 50 epochs...\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/50      1.63G       1.99      2.994       3.87      1.274         17        512: 100% ━━━━━━━━━━━━ 79/79 5.0it/s 15.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.5it/s 3.7s0.3s\n                   all        396        418   0.000833      0.237   0.000517   0.000253   0.000884      0.251   0.000559   0.000229\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/50      2.05G      1.861      2.457      2.335      1.246         14        512: 100% ━━━━━━━━━━━━ 79/79 5.9it/s 13.5s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.9it/s 3.4s0.3s\n                   all        396        418      0.467      0.211      0.206     0.0745      0.425      0.191      0.168     0.0585\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/50      2.07G      1.846       2.34      1.881      1.254         17        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.5s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.4it/s 3.8s0.3s\n                   all        396        418      0.668      0.318      0.359      0.152      0.611      0.304      0.324      0.131\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/50      2.08G      1.755      2.277      1.582      1.215         17        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.7it/s 3.5s0.3s\n                   all        396        418      0.534       0.37      0.345      0.127      0.474      0.347      0.295     0.0853\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/50      2.09G      1.789      2.255      1.476       1.22         18        512: 100% ━━━━━━━━━━━━ 79/79 6.4it/s 12.4s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.8it/s 3.4s0.3s\n                   all        396        418      0.664      0.369      0.379      0.141      0.672      0.388      0.392      0.152\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/50       2.1G      1.701      2.152      1.327      1.193         22        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.4s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.9it/s 3.3s0.2s\n                   all        396        418      0.605      0.396      0.407      0.166      0.575      0.373      0.371      0.145\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/50       2.1G       1.61      2.091      1.218      1.164         19        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.5s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.607      0.383      0.418      0.142      0.565      0.361      0.374      0.126\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/50       2.1G      1.583      2.023      1.168      1.128         16        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.1s0.2s\n                   all        396        418      0.601      0.368      0.384      0.155      0.566      0.347      0.347      0.122\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/50       2.1G      1.595      2.041      1.107      1.151         20        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 13.0s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.1s0.3s\n                   all        396        418      0.603      0.474      0.429       0.17      0.641      0.435      0.418       0.18\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/50       2.1G       1.55       1.92      1.101      1.134         10        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.627      0.419      0.407      0.129      0.662      0.423      0.426      0.136\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/50       2.1G      1.517      1.971      1.046      1.121         21        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.9it/s 3.4s0.2s\n                   all        396        418      0.558      0.447      0.442       0.17      0.591      0.412      0.423      0.157\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/50       2.1G      1.527      1.953      1.018      1.091         21        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.3s\n                   all        396        418      0.597      0.464      0.425      0.155      0.613      0.464      0.429      0.151\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/50       2.1G      1.504      1.899      1.044        1.1         19        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.8s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418       0.67      0.495      0.485       0.19      0.645      0.478      0.457       0.19\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/50       2.1G      1.447      1.848     0.9509      1.074         15        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.0it/s 3.2s0.2s\n                   all        396        418      0.662      0.507      0.509      0.212      0.711      0.464      0.481      0.187\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/50       2.1G      1.443      1.791     0.9438      1.068         16        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.0s0.2s\n                   all        396        418       0.54      0.493      0.435      0.157      0.592      0.445       0.42      0.154\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/50       2.1G      1.438      1.832     0.9568      1.067         22        512: 100% ━━━━━━━━━━━━ 79/79 6.0it/s 13.2s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.3s\n                   all        396        418      0.632      0.459      0.436      0.171      0.613      0.443      0.406       0.16\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/50       2.1G      1.435      1.815     0.9359      1.056         19        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.609      0.391      0.374      0.145      0.613      0.397      0.369      0.141\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/50       2.1G       1.42      1.798     0.8852      1.068         11        512: 100% ━━━━━━━━━━━━ 79/79 6.4it/s 12.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418      0.652      0.439      0.413      0.157      0.629      0.416      0.391      0.158\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/50       2.1G      1.453       1.88     0.9181      1.077         15        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.6s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.0it/s 3.2s0.2s\n                   all        396        418      0.626      0.417      0.397      0.117      0.677      0.409      0.402      0.122\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/50       2.1G      1.379      1.759     0.8579      1.039         16        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.0s0.2s\n                   all        396        418      0.605      0.414      0.395      0.142      0.598       0.41      0.379       0.13\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      21/50       2.1G      1.375      1.724     0.8588      1.034         21        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.1s0.2s\n                   all        396        418      0.626      0.456      0.424      0.144      0.656      0.455      0.425      0.153\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      22/50       2.1G       1.35      1.766     0.8475      1.035         18        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.6s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418      0.527      0.407      0.344       0.11       0.58      0.395      0.337       0.11\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      23/50       2.1G       1.34      1.665      0.816      1.033         25        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 3.0s0.2s\n                   all        396        418      0.656      0.429      0.401      0.144       0.66      0.431      0.388      0.132\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      24/50       2.1G      1.316      1.691     0.8014      1.017         18        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.691      0.423      0.395      0.132      0.686      0.414       0.39      0.135\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      25/50       2.1G      1.329      1.637     0.8053      1.009         18        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.736      0.476      0.495      0.188      0.739      0.462       0.47      0.173\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      26/50       2.1G      1.344      1.717     0.8227      1.015         17        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418      0.709      0.447      0.425      0.148      0.729      0.457      0.432      0.153\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      27/50       2.1G      1.317      1.713     0.7978       1.02         20        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.5s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418      0.726      0.431      0.455        0.2      0.722      0.421      0.437       0.19\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      28/50       2.1G      1.324      1.666      0.784      1.015         25        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418      0.659      0.443      0.422       0.13      0.665      0.469      0.422       0.13\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      29/50       2.1G      1.312      1.666     0.7628      1.018         13        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.5s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418      0.617      0.445      0.388      0.113      0.603      0.435      0.379      0.107\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      30/50       2.1G      1.269       1.61     0.7479     0.9947         16        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 3.0s0.2s\n                   all        396        418      0.678      0.426      0.426      0.158      0.647      0.419      0.408      0.143\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      31/50       2.1G      1.265      1.644     0.7483     0.9792         18        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.1s0.2s\n                   all        396        418      0.656      0.455       0.42      0.136      0.694      0.445      0.407      0.141\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      32/50       2.1G      1.248      1.585      0.731     0.9855         24        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.741      0.423      0.419       0.13      0.705      0.407      0.392      0.129\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      33/50       2.1G      1.218      1.539     0.7146     0.9898         11        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.8s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.0s0.2s\n                   all        396        418      0.657      0.421       0.38      0.115       0.63      0.402      0.357      0.113\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      34/50       2.1G      1.228      1.559     0.7137      0.971         18        512: 100% ━━━━━━━━━━━━ 79/79 6.3it/s 12.6s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.0it/s 3.2s0.2s\n                   all        396        418      0.673      0.458      0.445      0.155      0.641      0.459      0.433      0.151\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      35/50       2.1G      1.194      1.549     0.6874     0.9688         16        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 13.0s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.669      0.469      0.469      0.171      0.738      0.426       0.45       0.16\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      36/50       2.1G      1.216      1.557     0.6927     0.9639         18        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 13.0s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 3.0s0.2s\n                   all        396        418       0.63      0.423      0.398      0.124      0.606      0.405      0.374      0.115\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      37/50       2.1G      1.207      1.528     0.6787      0.971         25        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.1it/s 3.2s0.2s\n                   all        396        418      0.621       0.45      0.405      0.129      0.626      0.453      0.401      0.126\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      38/50       2.1G      1.195      1.536     0.6574     0.9654         22        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 2.9s0.2s\n                   all        396        418      0.736      0.455      0.439      0.164       0.72       0.45      0.433      0.167\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      39/50       2.1G      1.176       1.51     0.6662     0.9548         20        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.2it/s 3.1s0.2s\n                   all        396        418      0.697      0.462      0.434      0.158      0.703      0.437      0.416      0.155\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      40/50       2.1G      1.147      1.489     0.6486     0.9569         16        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.7s0.1s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.0it/s 3.2s0.2s\n                   all        396        418      0.657      0.455      0.427      0.145      0.658      0.447      0.424      0.141\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      41/50       2.1G      1.158       1.51     0.6412     0.9688         11        512: 100% ━━━━━━━━━━━━ 79/79 5.7it/s 13.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 3.0s0.2s\n                   all        396        418      0.597      0.403      0.377      0.123      0.605      0.388      0.361      0.116\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      42/50       2.1G       1.13       1.49     0.6157     0.9626         13        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 13.0s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 3.0s0.2s\n                   all        396        418      0.681      0.433      0.433      0.159      0.703      0.431      0.426      0.151\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      43/50       2.1G      1.106      1.461     0.6042     0.9511         15        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.0s0.2s\n                   all        396        418      0.668      0.426      0.416      0.135      0.691      0.409      0.402      0.138\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      44/50       2.1G      1.091      1.454     0.6027     0.9413         13        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.0s0.2s\n                   all        396        418      0.637      0.421      0.392       0.13      0.627      0.411      0.377      0.132\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      45/50       2.1G      1.063      1.459     0.5773     0.9316         14        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 13.0s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 2.9s0.2s\n                   all        396        418      0.625      0.438      0.393      0.125      0.697      0.404      0.392      0.124\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      46/50       2.1G      1.069      1.435     0.5663     0.9235         13        512: 100% ━━━━━━━━━━━━ 79/79 5.9it/s 13.4s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.0s0.2s\n                   all        396        418      0.681      0.423      0.406       0.14      0.686      0.431       0.41       0.14\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      47/50       2.1G      1.047      1.424     0.5667     0.9238         13        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 13.0s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 2.9s0.2s\n                   all        396        418      0.683      0.416      0.403      0.126      0.698       0.42      0.399      0.129\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      48/50       2.1G      1.041      1.392     0.5528     0.9294         13        512: 100% ━━━━━━━━━━━━ 79/79 6.2it/s 12.8s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 3.0s0.2s\n                   all        396        418      0.653      0.455      0.434      0.142      0.715      0.419      0.433      0.146\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      49/50       2.1G      1.033      1.394     0.5518     0.9167         14        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.4it/s 2.9s0.2s\n                   all        396        418       0.67       0.44       0.43      0.145       0.71      0.423       0.43      0.148\n\n      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      50/50       2.1G      1.013      1.405     0.5484     0.9131         13        512: 100% ━━━━━━━━━━━━ 79/79 6.1it/s 12.9s0.2s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 4.3it/s 3.0s0.2s\n                   all        396        418      0.681      0.439      0.422      0.143      0.689      0.431      0.417      0.143\n\n50 epochs completed in 0.227 hours.\nOptimizer stripped from /kaggle/working/runs/segment/yolov8_lung_seg7/weights/last.pt, 6.8MB\nOptimizer stripped from /kaggle/working/runs/segment/yolov8_lung_seg7/weights/best.pt, 6.8MB\n\nValidating /kaggle/working/runs/segment/yolov8_lung_seg7/weights/best.pt...\nUltralytics 8.3.226 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nYOLOv8n-seg summary (fused): 85 layers, 3,258,259 parameters, 0 gradients, 11.3 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 13/13 3.0it/s 4.3s0.2s\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        396        418      0.662      0.506      0.509      0.212      0.711      0.464       0.48      0.186\nSpeed: 0.2ms preprocess, 2.0ms inference, 0.0ms loss, 2.5ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/segment/yolov8_lung_seg7\u001b[0m\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# The training process automatically runs validation.\n# You can see metrics like mAP50-95 in the training output.\n# The best model weights are saved automatically.\n\n# Let's find the path to the best model\nbest_model_path = '/kaggle/working/runs/segment/yolov8_lung_seg2/weights/best.pt'\n\n# Load the best model\nmodel = YOLO(best_model_path)\n\n# Run validation again explicitly (optional)\nmetrics = model.val()\n\n# --- THIS IS THE CORRECTED LINE ---\n# We use metrics.seg instead of metrics.mask\nprint(f\"Validation Metrics (Mask mAP50): {metrics.seg.map50}\")\n\n# You can now find all your training results, graphs, and validation images\n# in the directory: /kaggle/working/runs/segment/yolov8_lung_seg2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:23:08.907114Z","iopub.execute_input":"2025-11-08T04:23:08.908144Z","iopub.status.idle":"2025-11-08T04:23:37.980530Z","shell.execute_reply.started":"2025-11-08T04:23:08.908106Z","shell.execute_reply":"2025-11-08T04:23:37.979832Z"}},"outputs":[{"name":"stdout","text":"Ultralytics 8.3.226 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\nYOLOv8x-seg summary (fused): 125 layers, 71,721,619 parameters, 0 gradients, 327.9 GFLOPs\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3350.2±522.7 MB/s, size: 333.8 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/lung_dataset_yolo/labels/val.cache... 396 images, 2 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 396/396 759.8Kit/s 0.0s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 25/25 1.1it/s 23.7s1.0ss\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n/usr/local/lib/python3.11/dist-packages/matplotlib/colors.py:721: RuntimeWarning: invalid value encountered in less\n  xa[xa < 0] = -1\n","output_type":"stream"},{"name":"stdout","text":"                   all        396        418      0.733      0.539      0.534      0.209       0.73      0.537      0.511      0.199\nSpeed: 1.1ms preprocess, 54.0ms inference, 0.0ms loss, 1.0ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/segment/val7\u001b[0m\nValidation Metrics (Mask mAP50): 0.5111666810464688\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import cv2\nimport torch\nimport nibabel as nib\nfrom tqdm import tqdm\nimport numpy as np\nfrom ultralytics import YOLO\nfrom IPython.display import HTML, display\nimport random\n\n# --- 1. Load your best trained model ---\nbest_model_path = '/kaggle/working/runs/segment/yolov8_lung_seg2/weights/best.pt'\nmodel = YOLO(best_model_path)\n\n# --- 2. Select a random sample from your validation set ---\n# (Using the val paths defined in Cell 4 of the original notebook)\n# sample_idx = random.randint(0, len(val_img_paths) - 1\nsample_idx = 11\nnii_image_path = val_img_paths[sample_idx]\nnii_label_path = val_lbl_paths[sample_idx]\n\nprint(f\"Visualizing sample: {os.path.basename(os.path.dirname(nii_image_path))}\")\n\n# --- 3. Load the 3D NIfTI image and label ---\nimg_nii = nib.load(nii_image_path)\nlbl_nii = nib.load(nii_label_path)\nimage_data = img_nii.get_fdata()\nlabel_data = lbl_nii.get_fdata()\n\n# --- 4. Setup Video Writer ---\noutput_video_path = '/kaggle/working/prediction_visualization.mp4'\nh, w, num_slices = image_data.shape\n# The final video frame will be 3 times as wide\nframe_size = (w * 3, h) \nfps = 10\n# Define the codec and create VideoWriter object\nfourcc = cv2.VideoWriter_fourcc(*'mp4v') \nvideo_writer = cv2.VideoWriter(output_video_path, fourcc, fps, frame_size)\n\n# --- 5. Process each slice and create the video ---\n# The tqdm wrapper creates the progress bar\nfor i in tqdm(range(num_slices), desc=\"Creating video...\"):\n    # Get the original slice and normalize it to 0-255\n    original_slice = image_data[:, :, i]\n    slice_normalized = cv2.normalize(original_slice, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    # Convert to 3-channel BGR for visualization and prediction\n    slice_bgr = cv2.cvtColor(slice_normalized, cv2.COLOR_GRAY2BGR)\n\n    # Get the ground truth mask for this slice\n    gt_mask = label_data[:, :, i].astype(np.uint8)\n\n    # --- Run Prediction ---\n    results = model.predict(slice_bgr, verbose=False)\n    \n    # --- Create the 3 visualization panels ---\n    # Panel 1: Original Image\n    panel_original = slice_bgr.copy()\n    cv2.putText(panel_original, \"Original Slice\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n\n    # Panel 2: Ground Truth Overlay\n    panel_gt = slice_bgr.copy()\n    gt_contours, _ = cv2.findContours(gt_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    cv2.drawContours(panel_gt, gt_contours, -1, (0, 255, 0), 2) # Green for Ground Truth\n    cv2.putText(panel_gt, \"Ground Truth\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n    \n    # Panel 3: Prediction Overlay\n    panel_pred = slice_bgr.copy()\n    cv2.putText(panel_pred, \"YOLO Prediction\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    # Check if the model made any predictions on this slice\n    if results[0].masks is not None:\n        pred_mask_tensor = results[0].masks.data[0]\n        pred_mask = pred_mask_tensor.cpu().numpy().astype(np.uint8)\n        pred_contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cv2.drawContours(panel_pred, pred_contours, -1, (0, 0, 255), 2) # Red for Prediction\n\n    # --- Combine panels and write to video ---\n    combined_frame = np.hstack((panel_original, panel_gt, panel_pred))\n    video_writer.write(combined_frame)\n\n# Release the video writer\nvideo_writer.release()\nprint(f\"\\nVideo saved successfully to {output_video_path}\")\n\n# --- 6. Display the video in the notebook ---\n# This creates an HTML5 video player to show the result\nvideo_html = f\"\"\"\n<video width=\"1024\" controls>\n  <source src=\"{output_video_path}\" type=\"video/mp4\">\n</video>\n\"\"\"\ndisplay(HTML(video_html))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:23:37.981538Z","iopub.execute_input":"2025-11-08T04:23:37.981780Z","iopub.status.idle":"2025-11-08T04:23:53.852989Z","shell.execute_reply.started":"2025-11-08T04:23:37.981757Z","shell.execute_reply":"2025-11-08T04:23:53.852412Z"}},"outputs":[{"name":"stdout","text":"Visualizing sample: lung_016.nii\n","output_type":"stream"},{"name":"stderr","text":"Creating video...: 100%|██████████| 228/228 [00:13<00:00, 16.33it/s]","output_type":"stream"},{"name":"stdout","text":"\nVideo saved successfully to /kaggle/working/prediction_visualization.mp4\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<video width=\"1024\" controls>\n  <source src=\"/kaggle/working/prediction_visualization.mp4\" type=\"video/mp4\">\n</video>\n"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import cv2\nimport torch\nimport nibabel as nib\nfrom tqdm import tqdm\nimport numpy as np\nfrom ultralytics import YOLO\nfrom IPython.display import HTML, display\nimport random\nimport os\nimport glob\n\n# --- 1. Load your best trained model ---\nbest_model_path = '/kaggle/working/runs/segment/yolov8_lung_seg2/weights/best.pt'\nmodel = YOLO(best_model_path)\n\n# --- 2. Get paths for the test data ---\nTEST_IMAGE_DIR = os.path.join(DATA_DIR, \"imagesTs\") # DATA_DIR was defined in Cell 2\ntest_image_paths = sorted(glob.glob(os.path.join(TEST_IMAGE_DIR, \"*/*.nii\")))\n\n# --- 3. Select a random sample from your test set ---\nsample_idx = random.randint(0, len(test_image_paths) - 1)\nnii_test_image_path = test_image_paths[sample_idx]\n\nprint(f\"Visualizing test sample: {os.path.basename(os.path.dirname(nii_test_image_path))}\")\n\n# --- 4. Load the 3D NIfTI image ---\nimg_nii = nib.load(nii_test_image_path)\nimage_data = img_nii.get_fdata()\n\n# --- 5. Setup Video Writer ---\noutput_test_video_path = '/kaggle/working/test_prediction_visualization.mp4'\nh, w, num_slices = image_data.shape\n# The video frame will be 2 times as wide (Original + Prediction)\nframe_size = (w * 2, h) \nfps = 10\nfourcc = cv2.VideoWriter_fourcc(*'mp4v') \ntest_video_writer = cv2.VideoWriter(output_test_video_path, fourcc, fps, frame_size)\n\n# --- 6. Process each slice and create the video ---\nfor i in tqdm(range(num_slices), desc=\"Creating test set video...\"):\n    # Get the original slice and normalize it to 0-255\n    original_slice = image_data[:, :, i]\n    slice_normalized = cv2.normalize(original_slice, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    # Convert to 3-channel BGR for visualization and prediction\n    slice_bgr = cv2.cvtColor(slice_normalized, cv2.COLOR_GRAY2BGR)\n\n    # --- Run Prediction ---\n    results = model.predict(slice_bgr, verbose=False)\n    \n    # --- Create the 2 visualization panels ---\n    # Panel 1: Original Image\n    panel_original = slice_bgr.copy()\n    cv2.putText(panel_original, \"Original Test Slice\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n\n    # Panel 2: Prediction Overlay\n    panel_pred = slice_bgr.copy()\n    cv2.putText(panel_pred, \"YOLO Prediction\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n    \n    if results[0].masks is not None:\n        pred_mask_tensor = results[0].masks.data[0]\n        pred_mask = pred_mask_tensor.cpu().numpy().astype(np.uint8)\n        pred_contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n        cv2.drawContours(panel_pred, pred_contours, -1, (0, 0, 255), 2) # Red for Prediction\n\n    # --- Combine panels and write to video ---\n    combined_frame = np.hstack((panel_original, panel_pred))\n    test_video_writer.write(combined_frame)\n\n# Release the video writer\ntest_video_writer.release()\nprint(f\"\\nTest set video saved successfully to {output_test_video_path}\")\n\n# --- 7. Display the video in the notebook ---\ntest_video_html = f\"\"\"\n<video width=\"1024\" controls>\n  <source src=\"{output_test_video_path}\" type=\"video/mp4\">\n</video>\n\"\"\"\ndisplay(HTML(test_video_html))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:23:53.853755Z","iopub.execute_input":"2025-11-08T04:23:53.854139Z","iopub.status.idle":"2025-11-08T04:24:39.608158Z","shell.execute_reply.started":"2025-11-08T04:23:53.854118Z","shell.execute_reply":"2025-11-08T04:24:39.607570Z"}},"outputs":[{"name":"stdout","text":"Visualizing test sample: lung_017.nii\n","output_type":"stream"},{"name":"stderr","text":"Creating test set video...: 100%|██████████| 580/580 [00:32<00:00, 17.72it/s]","output_type":"stream"},{"name":"stdout","text":"\nTest set video saved successfully to /kaggle/working/test_prediction_visualization.mp4\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n<video width=\"1024\" controls>\n  <source src=\"/kaggle/working/test_prediction_visualization.mp4\" type=\"video/mp4\">\n</video>\n"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"**# ANALYZER**\n","metadata":{}},{"cell_type":"code","source":"import nibabel as nib\nimport numpy as np\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom ultralytics import YOLO\n\nprint(\"--- Step 1: Creating Stage 2 'Analyzer' Dataset ---\")\n\n# --- 1. Load your trained YOLO model ---\n# Make sure this path is correct for your notebook\nbest_model_path = '/kaggle/working/runs/segment/yolov8_lung_seg2/weights/best.pt' \nmodel = YOLO(best_model_path)\n\n# --- 2. Define Output Dirs for the new dataset ---\nSTAGE2_DATA_DIR = \"/kaggle/working/stage_2_analyzer_data/\"\nCLASS_0_HEALTHY_DIR = os.path.join(STAGE2_DATA_DIR, \"class_0_healthy\") # False Positives\nCLASS_1_CANCER_DIR = os.path.join(STAGE2_DATA_DIR, \"class_1_cancer\")   # Real Tumors\nos.makedirs(CLASS_0_HEALTHY_DIR, exist_ok=True)\nos.makedirs(CLASS_1_CANCER_DIR, exist_ok=True)\n\n# --- 3. Get all your patient scans (from your original script) ---\n# This assumes 'train_img_paths', 'val_img_paths', 'train_lbl_paths', \n# and 'val_lbl_paths' are still in memory from your previous cells.\nall_image_paths = train_img_paths + val_img_paths\nall_label_paths = train_lbl_paths + val_lbl_paths\n\nprint(f\"Processing {len(all_image_paths)} patient scans to build Stage 2 dataset...\")\n\n# --- 4. Main Loop: Find Real Tumors and False Positives ---\npatch_id = 0\nfor img_p, lbl_p in tqdm(zip(all_image_paths, all_label_paths), total=len(all_image_paths)):\n    \n    img_nii = nib.load(img_p)\n    lbl_nii = nib.load(lbl_p)\n    image_data = img_nii.get_fdata()\n    label_data = lbl_nii.get_fdata()\n\n    patient_id = os.path.basename(os.path.dirname(img_p))\n\n    for i in range(image_data.shape[2]): # Loop through each 2D slice\n        slice_label = label_data[:, :, i].astype(np.uint8)\n        slice_image = image_data[:, :, i]\n        \n        # Normalize and convert for prediction\n        slice_normalized = cv2.normalize(slice_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n        slice_bgr = cv2.cvtColor(slice_normalized, cv2.COLOR_GRAY2BGR) # YOLO needs 3 channels\n\n        # --- A: Find and Save REAL Tumors (Ground Truth) ---\n        # This gives our model the \"Cancer\" examples\n        if np.sum(slice_label) > 0: # If there's a real tumor in this slice\n            contours, _ = cv2.findContours(slice_label, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n            for contour in contours:\n                x, y, w, h = cv2.boundingRect(contour)\n                # Crop the patch from the original (normalized) image\n                patch = slice_normalized[y:y+h, x:x+w]\n                if patch.size > 0:\n                    patch_filename = f\"{patient_id}_slice_{i}_gt_{patch_id}.png\"\n                    cv2.imwrite(os.path.join(CLASS_1_CANCER_DIR, patch_filename), patch)\n                    patch_id += 1\n\n        # --- B: Find and Save FALSE Positives (YOLO's Mistakes) ---\n        # This gives our model the \"Healthy\" (but tricky) examples\n        results = model.predict(slice_bgr, verbose=False)\n        \n        if results[0].masks is not None:\n            # Loop over each mask YOLO found\n            for mask_tensor in results[0].masks.data:\n                pred_mask = mask_tensor.cpu().numpy().astype(np.uint8)\n                \n                # Check if this prediction overlaps with the REAL tumor\n                # We add the masks: 0=nothing, 1=GT, 2=Pred, 3=Overlap\n                combined_mask = slice_label + (pred_mask * 2)\n                overlap_area = np.sum(combined_mask == 3)\n                \n                # If there's NO overlap, it's a False Positive\n                if overlap_area == 0:\n                    contours, _ = cv2.findContours(pred_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n                    for contour in contours:\n                        x, y, w, h = cv2.boundingRect(contour)\n                        # Crop the patch from the original (normalized) image\n                        patch = slice_normalized[y:y+h, x:x+w]\n                        if patch.size > 0:\n                            patch_filename = f\"{patient_id}_slice_{i}_fp_{patch_id}.png\"\n                            cv2.imwrite(os.path.join(CLASS_0_HEALTHY_DIR, patch_filename), patch)\n                            patch_id += 1\n\nprint(f\"\\n--- Stage 2 Dataset Creation Complete ---\")\nprint(f\"Found {len(os.listdir(CLASS_1_CANCER_DIR))} real tumor patches.\")\nprint(f\"Found {len(os.listdir(CLASS_0_HEALTHY_DIR))} false positive patches.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-08T04:24:39.608967Z","iopub.execute_input":"2025-11-08T04:24:39.609171Z"}},"outputs":[{"name":"stdout","text":"--- Step 1: Creating Stage 2 'Analyzer' Dataset ---\nProcessing 63 patient scans to build Stage 2 dataset...\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 31/63 [10:24<09:01, 16.93s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom skimage.feature import graycomatrix, graycoprops\nimport cv2\nimport os # We'll need os for the test at the end\n\nprint(\"--- Step 2: ECE Feature Extractor Function ---\")\n\ndef get_ece_features(image_patch):\n    \"\"\"\n    Takes a single (grayscale) image patch and returns\n    its ECE texture features based on GLCM.\n    \n    This works by measuring the spatial relationship of pixels,\n    quantifying texture with metrics from information theory.\n    \"\"\"\n    \n    # Ensure patch is 8-bit (skimage needs this)\n    if image_patch.dtype != np.uint8:\n        # Check if the image is already normalized (0-1)\n        if image_patch.max() <= 1.0:\n            image_patch = (image_patch * 255).astype(np.uint8)\n        else:\n            image_patch = cv2.normalize(image_patch, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n\n    # 1. Calculate the Gray-Level Co-occurrence Matrix (GLCM)\n    # We check 4 directions (0, 45, 90, 135 deg) and average them\n    glcm = graycomatrix(image_patch, \n                        distances=[5], # The pixel distance to check\n                        angles=[0, np.pi/4, np.pi/2, 3*np.pi/4], # The angles\n                        levels=256,\n                        symmetric=True, \n                        normed=True)\n\n    # 2. Extract the texture properties\n    # These are your ECE features!\n    contrast = np.mean(graycoprops(glcm, 'contrast'))\n    dissimilarity = np.mean(graycoprops(glcm, 'dissimilarity'))\n    homogeneity = np.mean(graycoprops(glcm, 'homogeneity'))\n    energy = np.mean(graycoprops(glcm, 'energy'))\n    correlation = np.mean(graycoprops(glcm, 'correlation'))\n    \n    # Return the ECE feature vector\n    return np.array([contrast, dissimilarity, homogeneity, energy, correlation])\n\n# --- Test the function ---\n# (Assuming the variables from Step 1 are still in memory)\ntry:\n    if len(os.listdir(CLASS_1_CANCER_DIR)) > 0:\n        sample_patch_path = os.path.join(CLASS_1_CANCER_DIR, os.listdir(CLASS_1_CANCER_DIR)[0])\n        sample_patch = cv2.imread(sample_patch_path, cv2.IMREAD_GRAYSCALE)\n        \n        if sample_patch is not None:\n            features = get_ece_features(sample_patch)\n            print(f\"Extracted {len(features)} ECE features from a sample patch.\")\n            print(f\"Features: [Contrast, Dissimilarity, Homogeneity, Energy, Correlation]\")\n            print(f\"Values: {features}\")\n        else:\n            print(\"Could not read sample patch for testing.\")\n    else:\n        print(\"No sample patches found in CLASS_1_CANCER_DIR to test.\")\nexcept NameError:\n    print(\"Run this cell again after running Step 1 to test the function.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport numpy as np\nimport cv2\nimport glob\nimport os\n\nprint(\"--- Step 3 (Pure PyTorch): Building the Hybrid ECE-CNN Analyzer ---\")\n\n# --- 1. Load all patch data and labels (Same as before) ---\nprint(\"Loading all patches and calculating ECE features...\")\nall_image_patches = []\nall_ece_features = []\nall_labels = []\n\nCLASS_0_HEALTHY_DIR = os.path.join(STAGE2_DATA_DIR, \"class_0_healthy\")\nCLASS_1_CANCER_DIR = os.path.join(STAGE2_DATA_DIR, \"class_1_cancer\")\n\nfor img_path in tqdm(glob.glob(os.path.join(CLASS_0_HEALTHY_DIR, \"*.png\"))):\n    patch = cv2.imread(img_path)\n    if patch is not None:\n        patch_resized = cv2.resize(patch, (128, 128))\n        patch_gray = cv2.cvtColor(patch_resized, cv2.COLOR_BGR2GRAY)\n        all_image_patches.append(patch_resized)\n        all_ece_features.append(get_ece_features(patch_gray))\n        all_labels.append(0)\n\nfor img_path in tqdm(glob.glob(os.path.join(CLASS_1_CANCER_DIR, \"*.png\"))):\n    patch = cv2.imread(img_path)\n    if patch is not None:\n        patch_resized = cv2.resize(patch, (128, 128))\n        patch_gray = cv2.cvtColor(patch_resized, cv2.COLOR_BGR2GRAY)\n        all_image_patches.append(patch_resized)\n        all_ece_features.append(get_ece_features(patch_gray))\n        all_labels.append(1)\n\n# --- 2. Convert to Tensors (PyTorch Format) ---\nX_images_np = np.array(all_image_patches)\nX_ece_np = np.array(all_ece_features)\ny_np = np.array(all_labels)\n\n# PyTorch needs (N, C, H, W) format, so we transpose\nX_images_np = np.transpose(X_images_np, (0, 3, 1, 2))\n\n# Convert to float32 Tensors, which PyTorch expects\nX_images_torch = torch.tensor(X_images_np, dtype=torch.float32) / 255.0 # Normalize\nX_ece_torch = torch.tensor(X_ece_np, dtype=torch.float32)\ny_torch = torch.tensor(y_np, dtype=torch.float32)\n\nprint(f\"\\nTotal samples: {len(y_torch)}\")\nprint(f\"Image tensor shape: {X_images_torch.shape}\")\nprint(f\"ECE tensor shape: {X_ece_torch.shape}\")\n\n# --- 3. Create a Custom PyTorch Dataset ---\nclass HybridDataset(Dataset):\n    def __init__(self, images, ece_features, labels):\n        self.images = images\n        self.ece_features = ece_features\n        self.labels = labels\n    \n    def __len__(self):\n        return len(self.labels)\n    \n    def __getitem__(self, idx):\n        return self.images[idx], self.ece_features[idx], self.labels[idx]\n\n# --- 4. Define the Hybrid Model Architecture in PyTorch ---\nclass HybridAnalyzer(nn.Module):\n    def __init__(self):\n        super(HybridAnalyzer, self).__init__()\n        \n        # Path 1: CNN (ResNet50)\n        self.cnn_base = models.resnet50(weights='IMAGENET1K_V1')\n        # Freeze all layers\n        for param in self.cnn_base.parameters():\n            param.requires_grad = False\n        # Replace the final layer\n        num_ftrs = self.cnn_base.fc.in_features\n        self.cnn_base.fc = nn.Linear(num_ftrs, 64) # Output 64 features\n        \n        # Path 2: ECE Features\n        self.ece_path = nn.Sequential(\n            nn.Linear(5, 16), # 5 ECE features in\n            nn.ReLU()\n        )\n        \n        # Fusion Head\n        self.fusion_head = nn.Sequential(\n            nn.Linear(64 + 16, 32), # 64 from CNN + 16 from ECE\n            nn.ReLU(),\n            nn.Linear(32, 1), # Final output\n            nn.Sigmoid()\n        )\n\n    def forward(self, x_image, x_ece):\n        x1 = self.cnn_base(x_image)   # Get CNN features\n        x2 = self.ece_path(x_ece)     # Get ECE features\n        x = torch.cat((x1, x2), dim=1) # Concatenate features\n        output = self.fusion_head(x)\n        return output\n\n# --- 5. Split Data and Create DataLoaders ---\n# We split the *indices* to keep data aligned\nindices = list(range(len(y_torch)))\ntrain_indices, val_indices = train_test_split(indices, test_size=0.2, random_state=42, stratify=y_np)\n\ntrain_dataset = HybridDataset(X_images_torch[train_indices], X_ece_torch[train_indices], y_torch[train_indices])\nval_dataset = HybridDataset(X_images_torch[val_indices], X_ece_torch[val_indices], y_torch[val_indices])\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n\n# --- 6. The Training Loop (This replaces .fit()) ---\nprint(\"\\n--- Training the Analyzer Model (PyTorch) ---\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nmodel = HybridAnalyzer().to(device)\ncriterion = nn.BCELoss() # Binary Cross Entropy Loss\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nnum_epochs = 30\nfor epoch in range(num_epochs):\n    model.train() # Set model to training mode\n    train_loss = 0.0\n    \n    for images, ece, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\"):\n        images, ece, labels = images.to(device), ece.to(device), labels.to(device)\n        \n        # Forward pass\n        outputs = model(images, ece)\n        loss = criterion(outputs, labels.unsqueeze(1)) # Add dimension for BCELoss\n        \n        # Backward pass and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n    \n    # --- Validation ---\n    model.eval() # Set model to evaluation mode\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, ece, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]  \"):\n            images, ece, labels = images.to(device), ece.to(device), labels.to(device)\n            \n            outputs = model(images, ece)\n            loss = criterion(outputs, labels.unsqueeze(1))\n            val_loss += loss.item()\n            \n            # Calculate accuracy\n            predicted = (outputs > 0.5).float()\n            total += labels.size(0)\n            correct += (predicted == labels.unsqueeze(1)).sum().item()\n            \n    avg_train_loss = train_loss / len(train_loader)\n    avg_val_loss = val_loss / len(val_loader)\n    val_accuracy = 100 * correct / total\n    \n    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n          f\"Train Loss: {avg_train_loss:.4f}, \"\n          f\"Val Loss: {avg_val_loss:.4f}, \"\n          f\"Val Accuracy: {val_accuracy:.2f}%\")\n\nprint(\"\\n--- Analyzer Training Complete! ---\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# --- Step 4: Save the Final Model ---\nanalyzer_model_path = \"/kaggle/working/analyzer_model.pth\"\ntorch.save(model.state_dict(), analyzer_model_path)\n\nprint(f\"Analyzer model saved to: {analyzer_model_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"ANIMATION","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\nimport nibabel as nib\nimport numpy as np\nimport cv2\nimport os\nfrom tqdm import tqdm\nfrom ultralytics import YOLO\nfrom IPython.display import HTML, display\n\nprint(\"--- Final Step: Creating the 'Smart Analyzer' Animation ---\")\n\n# --- 1. Define the Analyzer Model Architecture (Needs to be redefined to load weights) ---\n# (This is the same class definition from Step 3)\nclass HybridAnalyzer(nn.Module):\n    def __init__(self):\n        super(HybridAnalyzer, self).__init__()\n        self.cnn_base = models.resnet50(weights='IMAGENET1K_V1')\n        for param in self.cnn_base.parameters():\n            param.requires_grad = False\n        num_ftrs = self.cnn_base.fc.in_features\n        self.cnn_base.fc = nn.Linear(num_ftrs, 64)\n        self.ece_path = nn.Sequential(nn.Linear(5, 16), nn.ReLU())\n        self.fusion_head = nn.Sequential(\n            nn.Linear(64 + 16, 32),\n            nn.ReLU(),\n            nn.Linear(32, 1),\n            nn.Sigmoid()\n        )\n    def forward(self, x_image, x_ece):\n        x1 = self.cnn_base(x_image)\n        x2 = self.ece_path(x_ece)\n        x = torch.cat((x1, x2), dim=1)\n        output = self.fusion_head(x)\n        return output\n\n# --- 2. Load Your TWO Trained Models ---\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Load Stage 1: YOLO \"Finder\"\nyolo_model_path = '/kaggle/working/runs/segment/yolov8_lung_seg2/weights/best.pt'\nyolo_model = YOLO(yolo_model_path)\n\n# Load Stage 2: ECE \"Analyzer\"\nanalyzer_model_path = \"/kaggle/working/analyzer_model.pth\"\nanalyzer_model = HybridAnalyzer().to(device)\nanalyzer_model.load_state_dict(torch.load(analyzer_model_path, map_location=device))\nanalyzer_model.eval() # Set to evaluation mode\nprint(\"All models loaded successfully.\")\n\n# --- 3. Select a Test Scan ---\n# (Using the same test path loading from your original script)\nif 'test_image_paths' not in locals(): # Check if test_image_paths exists\n    TEST_IMAGE_DIR = os.path.join(DATA_DIR, \"imagesTs\")\n    test_image_paths = sorted(glob.glob(os.path.join(TEST_IMAGE_DIR, \"*/*.nii\")))\n    \nnii_test_image_path = test_image_paths[random.randint(0, len(test_image_paths) - 1)]\nprint(f\"Visualizing test sample: {os.path.basename(os.path.dirname(nii_test_image_path))}\")\n\nimg_nii = nib.load(nii_test_image_path)\nimage_data = img_nii.get_fdata()\n\n# --- 4. Setup Video Writer ---\noutput_final_video_path = '/kaggle/working/final_analyzer_video.mp4'\nh, w, num_slices = image_data.shape\nframe_size = (w * 2, h) # Original + Analyzer\nfps = 10\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nvideo_writer = cv2.VideoWriter(output_final_video_path, fourcc, fps, frame_size)\n\n# --- 5. Main Video Loop (Running the Full 2-Stage Pipeline) ---\nfor i in tqdm(range(num_slices), desc=\"Creating final animation...\"):\n    # --- Get Original Slice ---\n    original_slice = image_data[:, :, i]\n    slice_normalized = cv2.normalize(original_slice, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    slice_bgr = cv2.cvtColor(slice_normalized, cv2.COLOR_GRAY2BGR) # For YOLO\n    \n    panel_original = slice_bgr.copy()\n    cv2.putText(panel_original, \"Original Slice\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n    \n    panel_analyzer = slice_bgr.copy()\n    cv2.putText(panel_analyzer, \"ECE Analyzer Result\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n\n    # --- Stage 1: Run YOLO \"Finder\" ---\n    results = yolo_model.predict(slice_bgr, verbose=False)\n\n    if results[0].masks is not None:\n        for mask_tensor, box in zip(results[0].masks.data, results[0].boxes):\n            # Get the bounding box\n            x1, y1, x2, y2 = box.xyxy[0].int().cpu().numpy()\n            \n            # --- Prepare Patch for Analyzer ---\n            # Crop the patch from the 3-channel BGR image\n            patch_bgr = slice_bgr[y1:y2, x1:x2]\n            if patch_bgr.size == 0: continue\n            \n            # 1. Image Tensor\n            patch_resized = cv2.resize(patch_bgr, (128, 128))\n            patch_transposed = np.transpose(patch_resized, (2, 0, 1)) # C, H, W\n            patch_tensor = torch.tensor(patch_transposed, dtype=torch.float32).unsqueeze(0).to(device) / 255.0\n            \n            # 2. ECE Tensor\n            patch_gray = cv2.cvtColor(patch_resized, cv2.COLOR_BGR2GRAY)\n            ece_features = get_ece_features(patch_gray) # From Step 2\n            ece_tensor = torch.tensor(ece_features, dtype=torch.float32).unsqueeze(0).to(device)\n\n            # --- Stage 2: Run ECE \"Analyzer\" ---\n            with torch.no_grad():\n                prediction = analyzer_model(patch_tensor, ece_tensor)\n            \n            confidence = prediction.item()\n            \n            # --- Draw the Final Result ---\n            if confidence > 0.5: # It's CANCER\n                label = f\"CANCER ({confidence*100:.0f}%)\"\n                color = (0, 0, 255) # Red\n            else: # It's HEALTHY (False Positive)\n                label = f\"HEALTHY ({100-confidence*100:.0f}%)\"\n                color = (0, 255, 0) # Green\n                \n            # Draw the box\n            cv2.rectangle(panel_analyzer, (x1, y1), (x2, y2), color, 2)\n            # Draw the label\n            cv2.putText(panel_analyzer, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n\n    # --- Combine panels and write to video ---\n    combined_frame = np.hstack((panel_original, panel_analyzer))\n    video_writer.write(combined_frame)\n\nvideo_writer.release()\nprint(f\"\\nFinal animation saved to {output_final_video_path}\")\n\n# --- 6. Display the Final Video ---\nvideo_html = f\"\"\"\n<video width=\"1024\" controls>\n  <source src=\"{output_final_video_path}\" type=\"video/mp4\">\n</video>\n\"\"\"\ndisplay(HTML(video_html))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}